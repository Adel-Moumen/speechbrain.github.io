<!DOCTYPE html>
<html lang="en-US">
  <head>

    
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-146863989-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-146863989-1');
      </script>
    
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.6.1 -->
<title>SpeechBrain | A PyTorch-based Speech Toolkit.</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="SpeechBrain" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A PyTorch-based Speech Toolkit." />
<meta property="og:description" content="A PyTorch-based Speech Toolkit." />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="SpeechBrain" />
<script type="application/ld+json">
{"headline":"SpeechBrain","url":"http://localhost:4000/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://speechbrain.github.io/assets/logo_noname_rounded_small.png"}},"name":"SpeechBrain","description":"A PyTorch-based Speech Toolkit.","@type":"WebSite","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=">
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <img src="https://speechbrain.github.io/assets/logo_noname_rounded_small.png" id="logo" />
      <h1 class="project-name">SpeechBrain</h1>
      <h2 class="project-tagline">A PyTorch-based Speech Toolkit.</h2>
      <a href="index.html" class="btn">Home</a>
      <a href="team.html" class="btn">Our Team</a>

      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="the-project">The project</h1>

<p><strong>SpeechBrain</strong> is an <strong>open-source</strong> and <strong>all-in-one</strong> speech toolkit
relying on <a href="https://pytorch.org">PyTorch</a>.</p>

<p>The goal is to create a <em>single</em>, <em>flexible</em>, and <em>user-friendly</em> toolkit that can be used to easily develop state-of-the-art speech technologies, including systems for <strong>speech recognition</strong> (both end-to-end and HMM-DNN), <strong>speaker recognition</strong>, <strong>speech separation</strong>, <strong>multi-microphone signal processing</strong> (e.g, beamforming), <strong>self-supervised and unsupervised learning</strong>, <strong>speech contamination / augmentation</strong>,  and many others. The toolkit will be designed to be a <strong>stand-alone framework</strong>, but simple interfaces with well-known toolkits, such as <a href="http://kaldi-asr.org">Kaldi</a> will also be implemented.</p>

<p><strong>SpeechBrain</strong> is currently <strong>under development</strong> and has been announced in September 2019. A first alpha version will be available in the next months.</p>

<p><a href="https://youtu.be/XETiKbN9ojE">See a short introductory video on the SpeechBrain project</a></p>

<p>We are also happy to share a timeline for the project. The <strong>first release</strong> will allow the community to start developing and use the toolkit freely and fully. The <strong>second release</strong> is expected to propose the complete SpeechBrain experience with different tasks added by the community and the core development team. The <strong>private release</strong> only concerns specific collaborators that have an important expertise on different speech-related domains, please see the <em>How to collaborate</em> Section if interested!</p>

<p><img src="../assets/com.png?style=fullsize" alt="timeline" /></p>

<h1 id="why-speechbrain">Why SpeechBrain?</h1>
<p>Speech processing toolkits have gained popularity in the last years. For automatic speech recognition (ASR) purposes, for instance, <a href="http://kaldi-asr.org">Kaldi</a> is an established framework. Some other ASR toolkits have been recently developed using the Python language such as <a href="https://github.com/mravanelli/pytorch-kaldi">PyTorch-Kaldi</a>, <a href="https://github.com/pykaldi/pykaldi">PyKaldi</a>, and <a href="https://github.com/espnet/espnet">ESPnet</a>. Beyond speech recognition, a variety of other solutions have been developed for speech-related applications, such as speech separation, speech enhancement, speaker recognition, and language model training.</p>

<p>Even though many of these frameworks could be very helpful for the specific task for which they are designed, our experience in the field suggests that having a <em>single</em>, <em>efficient</em>, and <em>flexible</em> toolkit can significantly <strong>speed up research and development</strong> of speech and audio processing techniques. Indeed, it is significantly easier to familiarize oneself with a single toolkit than to learn several different frameworks. Moreover, the use of a <strong>single platform</strong> for different speech and audio applications makes it more natural to develop <strong>multi-task systems</strong> that jointly solve different problems. It is also easier to build a strong and fruitful community when considering a unique and self-contained framework.</p>

<h1 id="why-pytorch">Why PyTorch?</h1>
<p>To ensure the needed <em>flexibility</em> and the <em>user-friendliness</em> of our system, we think that our platform must be built on the top of PyTorch for the following reasons:</p>
<ul>
  <li>PyTorch is a well-designed, flexible, popular, and well-documented toolkit with a very large community.</li>
  <li>Most speech applications rely on deep learning and signal processing techniques, that can be naturally implemented in PyTorch.</li>
  <li>Processing steps are performed either on GPUs or CPUs.</li>
  <li>It is feasible to design end-to-end differentiable systems, where the gradient can potentially flow through all the different parts of the architecture, including parts solving different audio and speech tasks (*e.g. joint training, multi-task learning, cooperative learning).</li>
</ul>

<h1 id="toolkits">Toolkits</h1>
<p>During the project, we plan to collaborate with the PyTorch Audio team of Facebook and with NVIDIA, that has recently developed the Neural Modules toolkit (Nemo), which provides flexibility and modularity to accelerate speech applications.</p>

<h1 id="how-to-collaborate">How to collaborate</h1>
<p>A strong toolkit needs a strong community. While a core team will be dedicated to develop and maintain the core functionalities of SpeechBrain, we need the help of the entire community to extend this ambitious project to numerous and various applications. Feel free to contact us, if you are interested to contribute.</p>

<h1 id="join-us">Join us!</h1>
<p>Thanks to our <a href="#Sponsors">sponsors</a>, we are hiring talented interns (3-6 months internships) that will work at Mila (Montréal) with the core development team. The ideal candidate is a PhD student with a strong experience in both PyTorch and speech technologies. Send us your CV if you are interested in this opportunity!</p>

<h1 id="contact-us">Contact us</h1>
<p>If you are interested to collaborate or sponsor us, or if you simply want to hear more about this project, please <strong>contact us at <em>speechbrainproject@gmail.com</em></strong>.</p>

<h1 id="speechbrain-and-social-good">SpeechBrain and Social Good</h1>
<p>The development and use of SpeechBrain technologies are parts of a policy of concern for AI for the “social good”. Therefore, all partners, collaborators and participants declare having read the <a href="https://www.montrealdeclaration-responsibleai.com">Montreal Declaration for a responsible development of AI</a>, adhere to these principles and implement them as part of the SpeechBrain project.</p>

<h1 id="sponsors">Sponsors</h1>

<div class="row">

<div class="column3">
<div class="card">
<img src="https://speechbrain.github.io/assets/logo_mila_small.png" style="width:200px;" class="team_pic" />
<div class="container">
</div>
</div>
</div>

<div class="column3">
<div class="card">
<img src="https://speechbrain.github.io/assets/logo_nvidia.png" style="width:250px" class="team_pic" />
<div class="container">
</div>
</div>
</div>


<div class="column3">
<div class="card">
<img src="https://speechbrain.github.io/assets/logo_dolby.png" style="width:250px;" class="team_pic" />
<div class="container">
</div>
</div>
</div>
</div>

<div class="row">

<div class="column2">
<div class="card">
<img src="https://speechbrain.github.io/assets/samsung_official.png" style="width:300px; " class="team_pic" />
<div class="container">
</div>
</div>
</div>

<div class="column2">
<div class="card">
<img src="https://speechbrain.github.io/assets/logo_nuance.png" style="width:300px" class="team_pic" />
<div class="container">
</div>
</div>
</div>

</div>

<h1 id="partner-institutions">Partner Institutions</h1>

<p>Partner Institutions have accepted to collaborate within SpeechBrain by dedicating important human or hardware resources. They are involved in the decision process by participating in weekly organized meetings to ensure the mutual benefit generated by this partnership. If interested in becoming the next official partner, please <strong>contact us at <em>speechbrainproject@gmail.com</em></strong>.</p>

<div class="row">

<div class="column2">
<div class="card">
<img src="https://speechbrain.github.io/assets/lium_logo_official.png" style="width:300px; " class="team_pic" />
<div class="container">
</div>
</div>
</div>

<div class="column2">
<div class="card">
<img src="https://speechbrain.github.io/assets/logo_sherbrooke.jpg" style="width:300px" class="team_pic" />
<div class="container">
</div>
</div>
</div>

</div>

<h1 id="collaborators">Collaborators</h1>
<p>Collaborators are actors interested in contributing in the project. It could be individual or small groups of researchers, companies or anyone whiling to develop an important block that could be integrated within SpeechBrain. Active collaborators are invited to the meetings to better synchronize the development of the toolkit.</p>

<ul>
  <li>University of Oxford (UK)</li>
  <li>Institut de Recherche en Informatique de Toulouse (IRIT, FR)</li>
  <li>LINAGORA (FR)</li>
  <li>PyTorch</li>
  <li>IBM Research</li>
  <li>Fluent.ai</li>
  <li>Avignon University (FR)</li>
  <li>Aalto University (FI)</li>
  <li>Madras Institute Of Technology (IN)</li>
  <li>The Ohio State University (USA)
<!-- <img src="../assets/logo_oxford.png" alt="OX" style="width:125px" />
<img src="https://speechbrain.github.io/assets/logo_lia2.png" style="width:200px" />
<img src="https://speechbrain.github.io/assets/lium_logo_official.png" style="width:250px" />
<img src="https://speechbrain.github.io/assets/logo_pytorch.png" style="width:250px; margin-right:25px;" />
<img src="https://speechbrain.github.io/assets/logo_ibm.png" style="width:300px; margin-right:25px;" />
<img src="https://speechbrain.github.io/assets/logo_fluent.png" style="width:200px" /> --></li>
</ul>


      <footer class="site-footer">
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
