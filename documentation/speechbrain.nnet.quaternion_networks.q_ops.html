

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>speechbrain.nnet.quaternion_networks.q_ops module &mdash; SpeechBrain 0.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="speechbrain.nnet.transducer" href="speechbrain.nnet.transducer.html" />
    <link rel="prev" title="speechbrain.nnet.quaternion_networks.q_normalization module" href="speechbrain.nnet.quaternion_networks.q_normalization.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SpeechBrain
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Quick installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-via-pypi">Install via PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-locally">Install locally</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#test-installation">Test Installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experiment.html">Running an experiment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#yaml-basics">YAML basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#running-arguments">Running arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#tensor-format">Tensor format</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multigpu.html">Basics of multi-GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-data-parallel">Multi-GPU training using Data Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-distributed-data-parallel-ddp">Multi-GPU training using Distributed Data Parallel (DDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multigpu.html#with-multiple-machines-suppose-you-have-2-servers-with-2-gpus">With multiple machines (suppose you have 2 servers with 2 GPUs):</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#zen-of-speechbrain">Zen of Speechbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#how-to-get-your-code-in-speechbrain">How to get your code in SpeechBrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#python">Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#version">Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#formatting">Formatting</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#adding-dependencies">Adding dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#development-tools">Development tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#flake8">flake8</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pre-commit">pre-commit</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-commit-hooks">the git pre-commit hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-push-hooks">the git pre-push hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pytest-doctests">pytest doctests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#continuous-integration">Continuous integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#what-is-ci">What is CI?</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#ci-cd-pipelines">CI / CD Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#our-test-suite">Our test suite</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#pull-request-review-guide">Pull Request review guide</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="speechbrain.html">Core library (speechbrain)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="speechbrain.core.html">speechbrain.core module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.yaml.html">speechbrain.yaml module</a></li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.alignment.html">speechbrain.alignment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.alignment.aligner.html">speechbrain.alignment.aligner module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.dataio.html">speechbrain.dataio</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.batch.html">speechbrain.dataio.batch module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataio.html">speechbrain.dataio.dataio module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataloader.html">speechbrain.dataio.dataloader module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataset.html">speechbrain.dataio.dataset module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.encoder.html">speechbrain.dataio.encoder module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.legacy.html">speechbrain.dataio.legacy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.sampler.html">speechbrain.dataio.sampler module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.wer.html">speechbrain.dataio.wer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.decoders.html">speechbrain.decoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.ctc.html">speechbrain.decoders.ctc module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.seq2seq.html">speechbrain.decoders.seq2seq module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.transducer.html">speechbrain.decoders.transducer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lm.html">speechbrain.lm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.arpa.html">speechbrain.lm.arpa module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.counting.html">speechbrain.lm.counting module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.ngram.html">speechbrain.lm.ngram module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lobes.html">speechbrain.lobes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.augment.html">speechbrain.lobes.augment module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.features.html">speechbrain.lobes.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.models.html">speechbrain.lobes.models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.CRDNN.html">speechbrain.lobes.models.CRDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ContextNet.html">speechbrain.lobes.models.ContextNet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ECAPA_TDNN.html">speechbrain.lobes.models.ECAPA_TDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ESPnetVGG.html">speechbrain.lobes.models.ESPnetVGG module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.MetricGAN_D.html">speechbrain.lobes.models.MetricGAN_D module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.RNNLM.html">speechbrain.lobes.models.RNNLM module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.VanillaNN.html">speechbrain.lobes.models.VanillaNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.Xvector.html">speechbrain.lobes.models.Xvector module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.conv_tasnet.html">speechbrain.lobes.models.conv_tasnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.convolution.html">speechbrain.lobes.models.convolution module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.dual_path.html">speechbrain.lobes.models.dual_path module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.transformer.html">speechbrain.lobes.models.transformer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="speechbrain.nnet.html">speechbrain.nnet</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.CNN.html">speechbrain.nnet.CNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.RNN.html">speechbrain.nnet.RNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.activations.html">speechbrain.nnet.activations module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.attention.html">speechbrain.nnet.attention module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.containers.html">speechbrain.nnet.containers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.dropout.html">speechbrain.nnet.dropout module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.embedding.html">speechbrain.nnet.embedding module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.linear.html">speechbrain.nnet.linear module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.losses.html">speechbrain.nnet.losses module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.normalization.html">speechbrain.nnet.normalization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.pooling.html">speechbrain.nnet.pooling module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.schedulers.html">speechbrain.nnet.schedulers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.complex_networks.html">speechbrain.nnet.complex_networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_CNN.html">speechbrain.nnet.complex_networks.c_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_RNN.html">speechbrain.nnet.complex_networks.c_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_linear.html">speechbrain.nnet.complex_networks.c_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_normalization.html">speechbrain.nnet.complex_networks.c_normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_ops.html">speechbrain.nnet.complex_networks.c_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.loss.html">speechbrain.nnet.loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.stoi_loss.html">speechbrain.nnet.loss.stoi_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.transducer_loss.html">speechbrain.nnet.loss.transducer_loss module</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.html">speechbrain.nnet.quaternion_networks</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_CNN.html">speechbrain.nnet.quaternion_networks.q_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_RNN.html">speechbrain.nnet.quaternion_networks.q_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_linear.html">speechbrain.nnet.quaternion_networks.q_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_normalization.html">speechbrain.nnet.quaternion_networks.q_normalization module</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">speechbrain.nnet.quaternion_networks.q_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.transducer.html">speechbrain.nnet.transducer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.transducer.transducer_joint.html">speechbrain.nnet.transducer.transducer_joint module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.processing.html">speechbrain.processing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.NMF.html">speechbrain.processing.NMF module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html">speechbrain.processing.PLDA_LDA module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.decomposition.html">speechbrain.processing.decomposition module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.diarization.html">speechbrain.processing.diarization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#reference">Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#id1">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.features.html">speechbrain.processing.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.multi_mic.html">speechbrain.processing.multi_mic module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.multi_mic.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.multi_mic.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.signal_processing.html">speechbrain.processing.signal_processing module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html">speechbrain.processing.speech_augmentation module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.tokenizers.html">speechbrain.tokenizers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html">speechbrain.tokenizers.SentencePiece module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.utils.html">speechbrain.utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.Accuracy.html">speechbrain.utils.Accuracy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.DER.html">speechbrain.utils.DER module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.checkpoints.html">speechbrain.utils.checkpoints module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.convert_model.html">speechbrain.utils.convert_model module</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_pipeline.html">speechbrain.utils.data_pipeline module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_utils.html">speechbrain.utils.data_utils module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.depgraph.html">speechbrain.utils.depgraph module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.distributed.html">speechbrain.utils.distributed module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.edit_distance.html">speechbrain.utils.edit_distance module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.epoch_loop.html">speechbrain.utils.epoch_loop module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.logger.html">speechbrain.utils.logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.metric_stats.html">speechbrain.utils.metric_stats module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html">speechbrain.utils.parameter_transfer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.superpowers.html">speechbrain.utils.superpowers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.train_logger.html">speechbrain.utils.train_logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Runnable Tools (tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tools.compute_wer.html">tools.compute_wer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tools.compute_wer.html#usage">Usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SpeechBrain</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="speechbrain.html">speechbrain</a> &raquo;</li>
        
          <li><a href="speechbrain.nnet.html">speechbrain.nnet</a> &raquo;</li>
        
          <li><a href="speechbrain.nnet.quaternion_networks.html">speechbrain.nnet.quaternion_networks</a> &raquo;</li>
        
      <li>speechbrain.nnet.quaternion_networks.q_ops module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/speechbrain.nnet.quaternion_networks.q_ops.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-speechbrain.nnet.quaternion_networks.q_ops">
<span id="speechbrain-nnet-quaternion-networks-q-ops-module"></span><h1>speechbrain.nnet.quaternion_networks.q_ops module<a class="headerlink" href="#module-speechbrain.nnet.quaternion_networks.q_ops" title="Permalink to this headline">¶</a></h1>
<p>This library implements different operations needed by quaternion-
valued architectures.
This work is inspired by:
“Quaternion neural networks” - Parcollet T.
“Quaternion recurrent neural networks” - Parcollet T. et al.
“Quaternion convolutional neural networks for end-to-end automatic speech
recognition” - Parcollet T. et al.
“Deep quaternion networks” - Gaudet Chase J. et al.</p>
<dl class="docutils">
<dt>Authors</dt><dd><ul class="simple">
<li>Titouan Parcollet 2020</li>
</ul>
</dd>
</dl>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Classes:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward" title="speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">QuaternionLinearCustomBackward</span></code></a></td>
<td>This class redefine the backpropagation of a quaternion linear layer (not a spinor layer).</td>
</tr>
</tbody>
</table>
<p>Functions:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.affect_conv_init" title="speechbrain.nnet.quaternion_networks.q_ops.affect_conv_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">affect_conv_init</span></code></a></td>
<td>Applies the weight initialization function given to the parameters.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.affect_init" title="speechbrain.nnet.quaternion_networks.q_ops.affect_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">affect_init</span></code></a></td>
<td>Applies the weight initialization function given to the parameters.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.check_quaternion_input" title="speechbrain.nnet.quaternion_networks.q_ops.check_quaternion_input"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_quaternion_input</span></code></a></td>
<td>Check the quaternion-valued shape for a linear layer.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_op" title="speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_op"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quaternion_conv_op</span></code></a></td>
<td>Applies a quaternion convolution transformation to the incoming data: It is important to notice that the forward phase of a QCNN is defined as W * Inputs (with * equal to the Hamilton product).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_rotation_op" title="speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_rotation_op"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quaternion_conv_rotation_op</span></code></a></td>
<td>Applies a quaternion rotation transformation to the incoming data: The rotation W*x*W^t can be replaced by R*x following: <a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a> Works for unitary and non-unitary weights (they will be normalized).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_init" title="speechbrain.nnet.quaternion_networks.q_ops.quaternion_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quaternion_init</span></code></a></td>
<td>Returns a matrix of quaternion numbers initialized with the method described in “Quaternion Recurrent Neural Network ” - Parcollt T.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_op" title="speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_op"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quaternion_linear_op</span></code></a></td>
<td>Applies a quaternion linear transformation to the incoming data: It is important to notice that the forward phase of a QNN is defined as W * Inputs (with * equal to the Hamilton product).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_rotation_op" title="speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_rotation_op"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quaternion_linear_rotation_op</span></code></a></td>
<td>Applies a quaternion rotation transformation to the incoming data: The rotation W*x*W^t can be replaced by R*x following: <a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a> Works for unitary and non-unitary weights (they will be normalized).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.nnet.quaternion_networks.q_ops.unitary_init" title="speechbrain.nnet.quaternion_networks.q_ops.unitary_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unitary_init</span></code></a></td>
<td>Returns a matrix of unitary quaternion numbers.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward">
<em class="property">class </em><code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">QuaternionLinearCustomBackward</code><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#QuaternionLinearCustomBackward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>This class redefine the backpropagation of a quaternion linear layer
(not a spinor layer). By doing so, we can save up to 4x memory, but it
is also 2x slower than ‘quaternion_linear_op’. It should be used
within speechbrain.nnet.quaternion_networks.linear.QuaternionLinear.</p>
<dl class="py method">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward.forward">
<em class="property">static </em><code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">ctx</span></em>, <em><span class="n">input</span></em>, <em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">bias</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#QuaternionLinearCustomBackward.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a quaternion linear transformation to the incoming data:
It is important to notice that the forward phase of a QNN is defined
as W * Inputs (with * equal to the Hamilton product). The constructed
cat_kernels_4_quaternion is a modified version of the quaternion
representation so when we do torch.mm(Input,W) it’s equivalent
to W * Inputs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed. Shape: [batch*time, X].</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py method">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward.backward">
<em class="property">static </em><code class="descname">backward</code><span class="sig-paren">(</span><em><span class="n">ctx</span></em>, <em><span class="n">grad_output</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#QuaternionLinearCustomBackward.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.QuaternionLinearCustomBackward.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the backward phase of the forward call defined above. This
implementation follows the quaternion backpropagation of a quaternion
layer that can be found in “Quaternion neural networks” - Parcollet T.
Page 48.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed.</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_op">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">quaternion_linear_op</code><span class="sig-paren">(</span><em><span class="n">input</span></em>, <em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">bias</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#quaternion_linear_op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a quaternion linear transformation to the incoming data:
It is important to notice that the forward phase of a QNN is defined
as W * Inputs (with * equal to the Hamilton product). The constructed
cat_kernels_4_quaternion is a modified version of the quaternion
representation so when we do torch.mm(Input,W) it’s equivalent
to W * Inputs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed.</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_rotation_op">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">quaternion_linear_rotation_op</code><span class="sig-paren">(</span><em><span class="n">input</span></em>, <em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">bias</span></em>, <em><span class="n">scale</span></em>, <em><span class="n">zero_kernel</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#quaternion_linear_rotation_op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_linear_rotation_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a quaternion rotation transformation to the incoming data:
The rotation W*x*W^t can be replaced by R*x following:
<a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a>
Works for unitary and non-unitary weights (they will be normalized).
The initial size of the input must be a multiple of 4 with the real part
equal to zero. Rotations only affect the vector part of a quaternion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed.</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
<li><strong>scale</strong> (<em>torch.Parameter</em>) – In the context of a spinor neural network, multiple rotations of
the input vector x are performed and summed. Hence, the norm of
the output vector always increases with the number of layers, making
the neural network instable with deep configurations. The scale
parameters are learnable parameters that acts like gates by multiplying
the output vector with a small trainable parameter.</li>
<li><strong>zero_kernel</strong> (<em>torch.Parameter</em>) – The zero kernel is simply a tensor of zeros with require grad = False.
Its shape is equivalent to a quaternion component shape. In fact,
it is only needed to make the dimensions match when using the rotation
matrix : <a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_rotation_op">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">quaternion_conv_rotation_op</code><span class="sig-paren">(</span><em><span class="n">input</span></em>, <em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">bias</span></em>, <em><span class="n">scale</span></em>, <em><span class="n">zero_kernel</span></em>, <em><span class="n">stride</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">padding</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">groups</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">dilation</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">conv1d</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#quaternion_conv_rotation_op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_rotation_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a quaternion rotation transformation to the incoming data:
The rotation W*x*W^t can be replaced by R*x following:
<a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a>
Works for unitary and non-unitary weights (they will be normalized).
The initial size of the input must be a multiple of 4 with the real part
equal to zero. Rotations only affect the vector part of a quaternion.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed.</li>
<li><strong>conv1d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – If true, a 1D convolution operation will be applied. Otherwise, a 2D
convolution is called.</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
<li><strong>scale</strong> (<em>torch.Parameter</em>) – In the context of a spinor neural network, multiple rotations of
the input vector x are performed and summed. Hence, the norm of
the output vector always increases with the number of layers, making
the neural network instable with deep configurations. The scale
parameters are learnable parameters that acts like gates by multiplying
the output vector with a small trainable parameter.</li>
<li><strong>zero_kernel</strong> (<em>torch.Parameter</em>) – The zero kernel is simply a tensor of zeros with require grad = False.
Its shape is equivalent to a quaternion component shape. In fact,
it is only needed to make the dimensions match when using the rotation
matrix : <a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation</a></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_op">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">quaternion_conv_op</code><span class="sig-paren">(</span><em><span class="n">input</span></em>, <em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">bias</span></em>, <em><span class="n">stride</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">padding</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">groups</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">dilation</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></span></em>, <em><span class="n">conv1d</span><span class="p">:</span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#quaternion_conv_op"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_conv_op" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a quaternion convolution transformation to the incoming data:
It is important to notice that the forward phase of a QCNN is defined
as W * Inputs (with * equal to the Hamilton product). The constructed
cat_kernels_4_quaternion is a modified version of the quaternion
representation so when we do torch.mm(Input,W) it’s equivalent
to W * Inputs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+a9f9377 ))"><em>torch.Tensor</em></a>) – Quaternion input tensor to be transformed.</li>
<li><strong>conv1d</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – If true, a 1D convolution operation will be applied. Otherwise, a 2D
convolution is called.</li>
<li><strong>r_weight</strong> (<em>torch.Parameter</em>) – Real part of the quaternion weight matrix of this layer.</li>
<li><strong>i_weight</strong> (<em>torch.Parameter</em>) – First imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>j_weight</strong> (<em>torch.Parameter</em>) – Second imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>k_weight</strong> (<em>torch.Parameter</em>) – Third imaginary part of the quaternion weight matrix of this layer.</li>
<li><strong>bias</strong> (<em>torch.Parameter</em>) – </li>
<li><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Stride factor of the convolutional filters.</li>
<li><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Amount of padding. See torch.nn documentation for more information.</li>
<li><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – This option specifies the convolutional groups. See torch.nn
documentation for more information.</li>
<li><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Dilation factor of the convolutional filters.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.quaternion_init">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">quaternion_init</code><span class="sig-paren">(</span><em><span class="n">in_features</span></em>, <em><span class="n">out_features</span></em>, <em><span class="n">kernel_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">criterion</span><span class="o">=</span><span class="default_value">'glorot'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#quaternion_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.quaternion_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a matrix of quaternion numbers initialized with the method
described in “Quaternion Recurrent Neural Network ” - Parcollt T.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>in_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of real values of the input layer (quaternion // 4).</li>
<li><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of real values of the output layer (quaternion // 4).</li>
<li><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Kernel_size for convolutional layers (ex: (3,3)).</li>
<li><strong>criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (glorot, he)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.unitary_init">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">unitary_init</code><span class="sig-paren">(</span><em><span class="n">in_features</span></em>, <em><span class="n">out_features</span></em>, <em><span class="n">kernel_size</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">criterion</span><span class="o">=</span><span class="default_value">'he'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#unitary_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.unitary_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a matrix of unitary quaternion numbers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>in_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of real values of the input layer (quaternion // 4).</li>
<li><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of real values of the output layer (quaternion // 4).</li>
<li><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Kernel_size for convolutional layers (ex: (3,3)).</li>
<li><strong>criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (glorot, he)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.affect_init">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">affect_init</code><span class="sig-paren">(</span><em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">init_func</span></em>, <em><span class="n">init_criterion</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#affect_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.affect_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the weight initialization function given to the parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>r_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>i_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>j_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>k_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>init_func</strong> (<em>function</em>) – (unitary_init, quaternion_init)</li>
<li><strong>init_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (glorot, he)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.affect_conv_init">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">affect_conv_init</code><span class="sig-paren">(</span><em><span class="n">r_weight</span></em>, <em><span class="n">i_weight</span></em>, <em><span class="n">j_weight</span></em>, <em><span class="n">k_weight</span></em>, <em><span class="n">kernel_size</span></em>, <em><span class="n">init_func</span></em>, <em><span class="n">init_criterion</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#affect_conv_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.affect_conv_init" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the weight initialization function given to the parameters.
This is specificaly written for convolutional layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>r_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>i_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>j_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>k_weight</strong> (<em>torch.Parameters</em>) – (nb_quaternion_in, nb_quaternion_out)</li>
<li><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Kernel size.</li>
<li><strong>init_func</strong> (<em>function</em>) – (unitary_init, quaternion_init)</li>
<li><strong>init_criterion</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – (glorot, he)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.nnet.quaternion_networks.q_ops.check_quaternion_input">
<code class="descclassname">speechbrain.nnet.quaternion_networks.q_ops.</code><code class="descname">check_quaternion_input</code><span class="sig-paren">(</span><em><span class="n">input_shape</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/nnet/quaternion_networks/q_ops.html#check_quaternion_input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.nnet.quaternion_networks.q_ops.check_quaternion_input" title="Permalink to this definition">¶</a></dt>
<dd><p>Check the quaternion-valued shape for a linear layer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input_shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a>) – Expected shape of the input.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="speechbrain.nnet.transducer.html" class="btn btn-neutral float-right" title="speechbrain.nnet.transducer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="speechbrain.nnet.quaternion_networks.q_normalization.html" class="btn btn-neutral float-left" title="speechbrain.nnet.quaternion_networks.q_normalization module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, SpeechBrain

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>