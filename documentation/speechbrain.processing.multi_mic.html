

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>speechbrain.processing.multi_mic module &mdash; SpeechBrain 0.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="speechbrain.processing.signal_processing module" href="speechbrain.processing.signal_processing.html" />
    <link rel="prev" title="speechbrain.processing.features module" href="speechbrain.processing.features.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SpeechBrain
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Quick installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-via-pypi">Install via PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-locally">Install locally</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#test-installation">Test Installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experiment.html">Running an experiment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#yaml-basics">YAML basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#running-arguments">Running arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#tensor-format">Tensor format</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multigpu.html">Basics of multi-GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-data-parallel">Multi-GPU training using Data Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-distributed-data-parallel-ddp">Multi-GPU training using Distributed Data Parallel (DDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multigpu.html#with-multiple-machines-suppose-you-have-2-servers-with-2-gpus">With multiple machines (suppose you have 2 servers with 2 GPUs):</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#zen-of-speechbrain">Zen of Speechbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#how-to-get-your-code-in-speechbrain">How to get your code in SpeechBrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#python">Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#version">Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#formatting">Formatting</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#adding-dependencies">Adding dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#development-tools">Development tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#flake8">flake8</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pre-commit">pre-commit</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-commit-hooks">the git pre-commit hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-push-hooks">the git pre-push hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pytest-doctests">pytest doctests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#continuous-integration">Continuous integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#what-is-ci">What is CI?</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#ci-cd-pipelines">CI / CD Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#our-test-suite">Our test suite</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#pull-request-review-guide">Pull Request review guide</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="speechbrain.html">Core library (speechbrain)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="speechbrain.core.html">speechbrain.core module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.yaml.html">speechbrain.yaml module</a></li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.alignment.html">speechbrain.alignment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.alignment.aligner.html">speechbrain.alignment.aligner module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.dataio.html">speechbrain.dataio</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.batch.html">speechbrain.dataio.batch module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataio.html">speechbrain.dataio.dataio module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataloader.html">speechbrain.dataio.dataloader module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataset.html">speechbrain.dataio.dataset module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.encoder.html">speechbrain.dataio.encoder module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.legacy.html">speechbrain.dataio.legacy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.sampler.html">speechbrain.dataio.sampler module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.wer.html">speechbrain.dataio.wer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.decoders.html">speechbrain.decoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.ctc.html">speechbrain.decoders.ctc module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.seq2seq.html">speechbrain.decoders.seq2seq module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.transducer.html">speechbrain.decoders.transducer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lm.html">speechbrain.lm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.arpa.html">speechbrain.lm.arpa module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.counting.html">speechbrain.lm.counting module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.ngram.html">speechbrain.lm.ngram module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lobes.html">speechbrain.lobes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.augment.html">speechbrain.lobes.augment module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.features.html">speechbrain.lobes.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.models.html">speechbrain.lobes.models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.CRDNN.html">speechbrain.lobes.models.CRDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ContextNet.html">speechbrain.lobes.models.ContextNet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ECAPA_TDNN.html">speechbrain.lobes.models.ECAPA_TDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ESPnetVGG.html">speechbrain.lobes.models.ESPnetVGG module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.MetricGAN_D.html">speechbrain.lobes.models.MetricGAN_D module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.RNNLM.html">speechbrain.lobes.models.RNNLM module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.VanillaNN.html">speechbrain.lobes.models.VanillaNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.Xvector.html">speechbrain.lobes.models.Xvector module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.conv_tasnet.html">speechbrain.lobes.models.conv_tasnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.convolution.html">speechbrain.lobes.models.convolution module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.dual_path.html">speechbrain.lobes.models.dual_path module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.transformer.html">speechbrain.lobes.models.transformer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.nnet.html">speechbrain.nnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.CNN.html">speechbrain.nnet.CNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.RNN.html">speechbrain.nnet.RNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.activations.html">speechbrain.nnet.activations module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.attention.html">speechbrain.nnet.attention module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.containers.html">speechbrain.nnet.containers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.dropout.html">speechbrain.nnet.dropout module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.embedding.html">speechbrain.nnet.embedding module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.linear.html">speechbrain.nnet.linear module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.losses.html">speechbrain.nnet.losses module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.normalization.html">speechbrain.nnet.normalization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.pooling.html">speechbrain.nnet.pooling module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.schedulers.html">speechbrain.nnet.schedulers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.complex_networks.html">speechbrain.nnet.complex_networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_CNN.html">speechbrain.nnet.complex_networks.c_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_RNN.html">speechbrain.nnet.complex_networks.c_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_linear.html">speechbrain.nnet.complex_networks.c_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_normalization.html">speechbrain.nnet.complex_networks.c_normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_ops.html">speechbrain.nnet.complex_networks.c_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.loss.html">speechbrain.nnet.loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.stoi_loss.html">speechbrain.nnet.loss.stoi_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.transducer_loss.html">speechbrain.nnet.loss.transducer_loss module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.html">speechbrain.nnet.quaternion_networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_CNN.html">speechbrain.nnet.quaternion_networks.q_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_RNN.html">speechbrain.nnet.quaternion_networks.q_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_linear.html">speechbrain.nnet.quaternion_networks.q_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_normalization.html">speechbrain.nnet.quaternion_networks.q_normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_ops.html">speechbrain.nnet.quaternion_networks.q_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.transducer.html">speechbrain.nnet.transducer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.transducer.transducer_joint.html">speechbrain.nnet.transducer.transducer_joint module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="speechbrain.processing.html">speechbrain.processing</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.NMF.html">speechbrain.processing.NMF module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html">speechbrain.processing.PLDA_LDA module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.decomposition.html">speechbrain.processing.decomposition module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.diarization.html">speechbrain.processing.diarization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#reference">Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#id1">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.features.html">speechbrain.processing.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">speechbrain.processing.multi_mic module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.signal_processing.html">speechbrain.processing.signal_processing module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html">speechbrain.processing.speech_augmentation module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.speech_augmentation.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.tokenizers.html">speechbrain.tokenizers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html">speechbrain.tokenizers.SentencePiece module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.utils.html">speechbrain.utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.Accuracy.html">speechbrain.utils.Accuracy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.DER.html">speechbrain.utils.DER module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.checkpoints.html">speechbrain.utils.checkpoints module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.convert_model.html">speechbrain.utils.convert_model module</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_pipeline.html">speechbrain.utils.data_pipeline module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_utils.html">speechbrain.utils.data_utils module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.depgraph.html">speechbrain.utils.depgraph module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.distributed.html">speechbrain.utils.distributed module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.edit_distance.html">speechbrain.utils.edit_distance module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.epoch_loop.html">speechbrain.utils.epoch_loop module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.logger.html">speechbrain.utils.logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.metric_stats.html">speechbrain.utils.metric_stats module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html">speechbrain.utils.parameter_transfer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.superpowers.html">speechbrain.utils.superpowers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.train_logger.html">speechbrain.utils.train_logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Runnable Tools (tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tools.compute_wer.html">tools.compute_wer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tools.compute_wer.html#usage">Usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SpeechBrain</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="speechbrain.html">speechbrain</a> &raquo;</li>
        
          <li><a href="speechbrain.processing.html">speechbrain.processing</a> &raquo;</li>
        
      <li>speechbrain.processing.multi_mic module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/speechbrain.processing.multi_mic.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-speechbrain.processing.multi_mic">
<span id="speechbrain-processing-multi-mic-module"></span><h1>speechbrain.processing.multi_mic module<a class="headerlink" href="#module-speechbrain.processing.multi_mic" title="Permalink to this headline">¶</a></h1>
<p>Multi-microphone components.</p>
<p>This library contains functions for multi-microphone signal processing.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span><span class="p">,</span> <span class="n">ISTFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">GccPhat</span><span class="p">,</span> <span class="n">SrpPhat</span><span class="p">,</span> <span class="n">Music</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">DelaySum</span><span class="p">,</span> <span class="n">Mvdr</span><span class="p">,</span> <span class="n">Gev</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise_diff</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise_diff</span> <span class="o">=</span> <span class="n">xs_noise_diff</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise_loc</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_0.70225_-0.70225_0.11704.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise_loc</span> <span class="o">=</span>  <span class="n">xs_noise_loc</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span> <span class="c1"># sampling rate</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn_diff</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise_diff</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn_loc</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise_loc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_diffused_noise</span> <span class="o">=</span> <span class="n">ss</span> <span class="o">+</span> <span class="n">nn_diff</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_localized_noise</span> <span class="o">=</span> <span class="n">ss</span> <span class="o">+</span> <span class="n">nn_loc</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Delay-and-Sum Beamforming with GCC-PHAT localization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">delaysum</span> <span class="o">=</span> <span class="n">DelaySum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">istft</span> <span class="o">=</span> <span class="n">ISTFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs_diffused_noise</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys_ds</span> <span class="o">=</span> <span class="n">delaysum</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">tdoas</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys_ds</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys_ds</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Mvdr Beamforming with SRP-PHAT localization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mvdr</span> <span class="o">=</span> <span class="n">Mvdr</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">srpphat</span> <span class="o">=</span> <span class="n">SrpPhat</span><span class="p">(</span><span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">srpphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys_mvdr</span> <span class="o">=</span> <span class="n">mvdr</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">XXs</span><span class="p">,</span> <span class="n">doas</span><span class="p">,</span> <span class="n">doa_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys_mvdr</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys_mvdr</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Mvdr Beamforming with MUSIC localization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">music</span> <span class="o">=</span> <span class="n">Music</span><span class="p">(</span><span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">music</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys_mvdr2</span> <span class="o">=</span> <span class="n">mvdr</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">XXs</span><span class="p">,</span> <span class="n">doas</span><span class="p">,</span> <span class="n">doa_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys_mvdr2</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys_mvdr2</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># GeV Beamforming</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gev</span> <span class="o">=</span> <span class="n">Gev</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs_localized_noise</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ss</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">ss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Nn</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">nn_loc</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SSs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Ss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">NNs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Nn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys_gev</span> <span class="o">=</span> <span class="n">gev</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">SSs</span><span class="p">,</span> <span class="n">NNs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys_gev</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys_gev</span><span class="p">)</span>
</pre></div>
</div>
<dl class="docutils">
<dt>Authors:</dt><dd><ul class="simple">
<li>William Aris</li>
<li>Francois Grondin</li>
</ul>
</dd>
</dl>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Classes:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.Covariance" title="speechbrain.processing.multi_mic.Covariance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Covariance</span></code></a></td>
<td>Computes the covariance matrices of the signals.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.DelaySum" title="speechbrain.processing.multi_mic.DelaySum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DelaySum</span></code></a></td>
<td>Performs delay and sum beamforming by using the TDOAs and the first channel as a reference.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.GccPhat" title="speechbrain.processing.multi_mic.GccPhat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GccPhat</span></code></a></td>
<td>Generalized Cross-Correlation with Phase Transform localization.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.Gev" title="speechbrain.processing.multi_mic.Gev"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Gev</span></code></a></td>
<td>Generalized EigenValue decomposition (GEV) Beamforming.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.Music" title="speechbrain.processing.multi_mic.Music"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Music</span></code></a></td>
<td>Multiple Signal Classification (MUSIC) localization.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.Mvdr" title="speechbrain.processing.multi_mic.Mvdr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Mvdr</span></code></a></td>
<td>Perform minimum variance distortionless response (MVDR) beamforming by using an input signal in the frequency domain, its covariance matrices and tdoas (to compute a steering vector).</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.SrpPhat" title="speechbrain.processing.multi_mic.SrpPhat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SrpPhat</span></code></a></td>
<td>Steered-Response Power with Phase Transform Localization.</td>
</tr>
</tbody>
</table>
<p>Functions:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.doas2taus" title="speechbrain.processing.multi_mic.doas2taus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">doas2taus</span></code></a></td>
<td>This function converts directions of arrival (xyz coordinates expressed in meters) in time differences of arrival (expressed in samples).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.sphere" title="speechbrain.processing.multi_mic.sphere"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sphere</span></code></a></td>
<td>This function generates cartesian coordinates (xyz) for a set of points forming a 3D sphere.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.steering" title="speechbrain.processing.multi_mic.steering"><code class="xref py py-obj docutils literal notranslate"><span class="pre">steering</span></code></a></td>
<td>This function computes a steering vector by using the time differences of arrival for each channel (in samples) and the number of bins (n_fft).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.multi_mic.tdoas2taus" title="speechbrain.processing.multi_mic.tdoas2taus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tdoas2taus</span></code></a></td>
<td>This function selects the tdoas of each channel and put them in a tensor.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="speechbrain.processing.multi_mic.Covariance">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">Covariance</code><span class="sig-paren">(</span><em><span class="n">average</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Covariance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Covariance" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes the covariance matrices of the signals.</p>
<dl class="docutils">
<dt>average<span class="classifier">bool</span></dt><dd>Informs the module if it should return an average
(computed on the time dimension) of the covariance
matrices. The Default value is True.</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs_speech</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 1001, 201, 2, 10])</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.Covariance.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">Xs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Covariance.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Covariance.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>This method uses the utility function _cov to compute covariance
matrices. Therefore, the result has the following format:
(batch, time_step, n_fft/2 + 1, 2, n_mics + n_pairs).</p>
<p>The order on the last dimension corresponds to the triu_indices for a
square matrix. For instance, if we have 4 channels, we get the following
order: (0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 2), (2, 3)
and (3, 3). Therefore, XXs[…, 0] corresponds to channels (0, 0) and XXs[…, 1]
corresponds to channels (0, 1).</p>
<dl class="docutils">
<dt>Xs<span class="classifier">tensor</span></dt><dd>A batch of audio signals in the frequency domain.
The tensor must have the following format:
(batch, time_step, n_fft/2 + 1, 2, n_mics)</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.Covariance.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.Covariance.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.DelaySum">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">DelaySum</code><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#DelaySum"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.DelaySum" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Performs delay and sum beamforming by using the TDOAs and
the first channel as a reference.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span><span class="p">,</span> <span class="n">ISTFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">GccPhat</span><span class="p">,</span> <span class="n">DelaySum</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span> <span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channel]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span>  <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#[batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs_speech</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">delaysum</span> <span class="o">=</span> <span class="n">DelaySum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">istft</span> <span class="o">=</span> <span class="n">ISTFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys</span> <span class="o">=</span> <span class="n">delaysum</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">tdoas</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.DelaySum.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">Xs</span></em>, <em><span class="n">localization_tensor</span></em>, <em><span class="n">doa_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em><span class="n">mics</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">fs</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">c</span><span class="o">=</span><span class="default_value">343.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#DelaySum.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.DelaySum.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>This method computes a steering vector by using the TDOAs/DOAs and
then calls the utility function _delaysum to perform beamforming.
The result has the following format: (batch, time_step, n_fft, 2, 1).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>Xs</strong> (<em>tensor</em>) – A batch of audio signals in the frequency domain.
The tensor must have the following format:
(batch, time_step, n_fft/2 + 1, 2, n_mics)</li>
<li><strong>localization_tensor</strong> (<em>tensor</em>) – A tensor containing either time differences of arrival (TDOAs)
(in samples) for each timestamp or directions of arrival (DOAs)
(xyz coordinates in meters). If localization_tensor represents
TDOAs, then its format is (batch, time_steps, n_mics + n_pairs).
If localization_tensor represents DOAs, then its format is
(batch, time_steps, 3)</li>
<li><strong>doa_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – The user needs to set this parameter to True if localization_tensor
represents DOAs instead of TDOAs. Its default value is set to False.</li>
<li><strong>mics</strong> (<em>tensor</em>) – The cartesian position (xyz coordinates in meters) of each microphone.
The tensor must have the following format (n_mics, 3). This
parameter is only mandatory when localization_tensor represents
DOAs.</li>
<li><strong>fs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The sample rate in Hertz of the signals. This parameter is only
mandatory when localization_tensor represents DOAs.</li>
<li><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The speed of sound in the medium. The speed is expressed in meters
per second and the default value of this parameter is 343 m/s. This
parameter is only used when localization_tensor represents DOAs.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.DelaySum.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.DelaySum.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.Mvdr">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">Mvdr</code><span class="sig-paren">(</span><em><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-20</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Mvdr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Mvdr" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Perform minimum variance distortionless response (MVDR) beamforming
by using an input signal in the frequency domain, its covariance matrices
and tdoas (to compute a steering vector).</p>
<blockquote>
<div><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span><span class="p">,</span> <span class="n">ISTFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">GccPhat</span><span class="p">,</span> <span class="n">DelaySum</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channel]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span>  <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#[batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs_speech</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mvdr</span> <span class="o">=</span> <span class="n">Mvdr</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">istft</span> <span class="o">=</span> <span class="n">ISTFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys</span> <span class="o">=</span> <span class="n">mvdr</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">XXs</span><span class="p">,</span> <span class="n">tdoas</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.Mvdr.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">Xs</span></em>, <em><span class="n">XXs</span></em>, <em><span class="n">localization_tensor</span></em>, <em><span class="n">doa_mode</span><span class="o">=</span><span class="default_value">False</span></em>, <em><span class="n">mics</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">fs</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">c</span><span class="o">=</span><span class="default_value">343.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Mvdr.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Mvdr.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>This method computes a steering vector before using the
utility function _mvdr to perform beamforming. The result has
the following format: (batch, time_step, n_fft, 2, 1).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>Xs</strong> (<em>tensor</em>) – A batch of audio signals in the frequency domain.
The tensor must have the following format:
(batch, time_step, n_fft/2 + 1, 2, n_mics)</li>
<li><strong>XXs</strong> (<em>tensor</em>) – The covariance matrices of the input signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs)</li>
<li><strong>localization_tensor</strong> (<em>tensor</em>) – A tensor containing either time differences of arrival (TDOAs)
(in samples) for each timestamp or directions of arrival (DOAs)
(xyz coordinates in meters). If localization_tensor represents
TDOAs, then its format is (batch, time_steps, n_mics + n_pairs).
If localization_tensor represents DOAs, then its format is
(batch, time_steps, 3)</li>
<li><strong>doa_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – The user needs to set this parameter to True if localization_tensor
represents DOAs instead of TDOAs. Its default value is set to False.</li>
<li><strong>mics</strong> (<em>tensor</em>) – The cartesian position (xyz coordinates in meters) of each microphone.
The tensor must have the following format (n_mics, 3). This
parameter is only mandatory when localization_tensor represents
DOAs.</li>
<li><strong>fs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The sample rate in Hertz of the signals. This parameter is only
mandatory when localization_tensor represents DOAs.</li>
<li><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The speed of sound in the medium. The speed is expressed in meters
per second and the default value of this parameter is 343 m/s. This
parameter is only used when localization_tensor represents DOAs.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.Mvdr.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.Mvdr.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.Gev">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">Gev</code><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Gev"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Gev" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generalized EigenValue decomposition (GEV) Beamforming.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span><span class="p">,</span> <span class="n">ISTFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Gev</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span>  <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_0.70225_-0.70225_0.11704.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nn</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">ss</span> <span class="o">+</span> <span class="n">nn</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gev</span> <span class="o">=</span> <span class="n">Gev</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">istft</span> <span class="o">=</span> <span class="n">ISTFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ss</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">ss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Nn</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">nn</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">SSs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Ss</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">NNs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Nn</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ys</span> <span class="o">=</span> <span class="n">gev</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">SSs</span><span class="p">,</span> <span class="n">NNs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ys</span> <span class="o">=</span> <span class="n">istft</span><span class="p">(</span><span class="n">Ys</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.Gev.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">Xs</span></em>, <em><span class="n">SSs</span></em>, <em><span class="n">NNs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Gev.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Gev.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>This method uses the utility function _gev to perform generalized
eigenvalue decomposition beamforming. Therefore, the result has
the following format: (batch, time_step, n_fft, 2, 1).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>Xs</strong> (<em>tensor</em>) – A batch of audio signals in the frequency domain.
The tensor must have the following format:
(batch, time_step, n_fft/2 + 1, 2, n_mics).</li>
<li><strong>SSs</strong> (<em>tensor</em>) – The covariance matrices of the target signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs).</li>
<li><strong>NNs</strong> (<em>tensor</em>) – The covariance matrices of the noise signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.Gev.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.Gev.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.GccPhat">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">GccPhat</code><span class="sig-paren">(</span><em><span class="n">tdoa_max</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-20</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#GccPhat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.GccPhat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Generalized Cross-Correlation with Phase Transform localization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tdoa_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Specifies a range to search for delays. For example, if
tdoa_max = 10, the method will restrict its search for delays
between -10 and 10 samples. This parameter is optional and its
default value is None. When tdoa_max is None, the method will
search for delays between -n_fft/2 and n_fft/2 (full range).</li>
<li><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – A small value to avoid divisions by 0 with the phase transformation.
The default value is 1e-20.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span><span class="p">,</span> <span class="n">ISTFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">GccPhat</span><span class="p">,</span> <span class="n">DelaySum</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channel]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span>  <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#[batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs_speech</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.GccPhat.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">XXs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#GccPhat.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.GccPhat.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform generalized cross-correlation with phase transform localization
by using the utility function _gcc_phat and by extracting the delays (in samples)
before performing a quadratic interpolation to improve the accuracy.
The result has the format: (batch, time_steps, n_mics + n_pairs).</p>
<p>The order on the last dimension corresponds to the triu_indices for a
square matrix. For instance, if we have 4 channels, we get the following
order: (0, 0), (0, 1), (0, 2), (0, 3), (1, 1), (1, 2), (1, 3), (2, 2), (2, 3)
and (3, 3). Therefore, delays[…, 0] corresponds to channels (0, 0) and delays[…, 1]
corresponds to channels (0, 1).</p>
<dl class="docutils">
<dt>XXs<span class="classifier">tensor</span></dt><dd>The covariance matrices of the input signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs).</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.GccPhat.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.GccPhat.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.SrpPhat">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">SrpPhat</code><span class="sig-paren">(</span><em><span class="n">mics</span></em>, <em><span class="n">space</span><span class="o">=</span><span class="default_value">'sphere'</span></em>, <em><span class="n">sample_rate</span><span class="o">=</span><span class="default_value">16000</span></em>, <em><span class="n">speed_sound</span><span class="o">=</span><span class="default_value">343.0</span></em>, <em><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-20</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#SrpPhat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.SrpPhat" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Steered-Response Power with Phase Transform Localization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mics</strong> (<em>tensor</em>) – The cartesian coordinates (xyz) in meters of each microphone.
The tensor must have the following format (n_mics, 3).</li>
<li><strong>space</strong> (<em>string</em>) – If this parameter is set to ‘sphere’, the localization will
be done in 3D by searching in a sphere of possible doas. If
it set to ‘circle’, the search will be done in 2D by searching
in a circle. By default, this parameter is set to ‘sphere’.
Note: The ‘circle’ option isn’t implemented yet.</li>
<li><strong>sample_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The sample rate in Hertz of the signals to perform SRP-PHAT on.
By default, this parameter is set to 16000 Hz.</li>
<li><strong>speed_sound</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The speed of sound in the medium. The speed is expressed in meters
per second and the default value of this parameter is 343 m/s.</li>
<li><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – A small value to avoid errors like division by 0. The default value
of this parameter is 1e-20.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">SrpPhat</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss1</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns1</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs1</span> <span class="o">=</span> <span class="n">ss1</span> <span class="o">+</span> <span class="n">ns1</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss2</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns2</span> <span class="o">=</span> <span class="mf">0.20</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs2</span> <span class="o">=</span> <span class="n">ss2</span> <span class="o">+</span> <span class="n">ns2</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ss1</span><span class="p">,</span><span class="n">ss2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ns1</span><span class="p">,</span><span class="n">ns2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">xs1</span><span class="p">,</span><span class="n">xs2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">srpphat</span> <span class="o">=</span> <span class="n">SrpPhat</span><span class="p">(</span><span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">srpphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.SrpPhat.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">XXs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#SrpPhat.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.SrpPhat.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform SRP-PHAT localization on a signal by computing a steering
vector and then by using the utility function _srp_phat to extract the doas.
The result is a tensor containing the directions of arrival (xyz coordinates
(in meters) in the direction of the sound source). The output tensor
has the format (batch, time_steps, 3).</p>
<p>This localization method uses Global Coherence Field (GCF):
<a class="reference external" href="https://www.researchgate.net/publication/221491705_Speaker_localization_based_on_oriented_global_coherence_field">https://www.researchgate.net/publication/221491705_Speaker_localization_based_on_oriented_global_coherence_field</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>XXs</strong> (<em>tensor</em>) – The covariance matrices of the input signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.SrpPhat.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.SrpPhat.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.multi_mic.Music">
<em class="property">class </em><code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">Music</code><span class="sig-paren">(</span><em><span class="n">mics</span></em>, <em><span class="n">space</span><span class="o">=</span><span class="default_value">'sphere'</span></em>, <em><span class="n">sample_rate</span><span class="o">=</span><span class="default_value">16000</span></em>, <em><span class="n">speed_sound</span><span class="o">=</span><span class="default_value">343.0</span></em>, <em><span class="n">eps</span><span class="o">=</span><span class="default_value">1e-20</span></em>, <em><span class="n">n_sig</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Music"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Music" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multiple Signal Classification (MUSIC) localization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mics</strong> (<em>tensor</em>) – The cartesian coordinates (xyz) in meters of each microphone.
The tensor must have the following format (n_mics, 3).</li>
<li><strong>space</strong> (<em>string</em>) – If this parameter is set to ‘sphere’, the localization will
be done in 3D by searching in a sphere of possible doas. If
it set to ‘circle’, the search will be done in 2D by searching
in a circle. By default, this parameter is set to ‘sphere’.
Note: The ‘circle’ option isn’t implemented yet.</li>
<li><strong>sample_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The sample rate in Hertz of the signals to perform SRP-PHAT on.
By default, this parameter is set to 16000 Hz.</li>
<li><strong>speed_sound</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The speed of sound in the medium. The speed is expressed in meters
per second and the default value of this parameter is 343 m/s.</li>
<li><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – A small value to avoid errors like division by 0. The default value
of this parameter is 1e-20.</li>
<li><strong>n_sig</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – An estimation of the number of sound sources. The default value is set
to one source.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">SrpPhat</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">xs_speech</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">xs_noise</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss1</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns1</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs1</span> <span class="o">=</span> <span class="n">ss1</span> <span class="o">+</span> <span class="n">ns1</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss2</span> <span class="o">=</span> <span class="n">xs_speech</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns2</span> <span class="o">=</span> <span class="mf">0.20</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs2</span> <span class="o">=</span> <span class="n">ss2</span> <span class="o">+</span> <span class="n">ns2</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ss1</span><span class="p">,</span><span class="n">ss2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">ns1</span><span class="p">,</span><span class="n">ns2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">xs1</span><span class="p">,</span><span class="n">xs2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">music</span> <span class="o">=</span> <span class="n">Music</span><span class="p">(</span><span class="n">mics</span><span class="o">=</span><span class="n">mics</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">music</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.multi_mic.Music.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">XXs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#Music.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.Music.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform MUSIC localization on a signal by computing a steering
vector and then by using the utility function _music to extract the doas.
The result is a tensor containing the directions of arrival (xyz coordinates
(in meters) in the direction of the sound source). The output tensor
has the format (batch, time_steps, 3).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>XXs</strong> (<em>tensor</em>) – The covariance matrices of the input signal. The tensor must
have the format (batch, time_steps, n_fft/2 + 1, 2, n_mics + n_pairs).</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.multi_mic.Music.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.multi_mic.Music.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="speechbrain.processing.multi_mic.doas2taus">
<code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">doas2taus</code><span class="sig-paren">(</span><em><span class="n">doas</span></em>, <em><span class="n">mics</span></em>, <em><span class="n">fs</span></em>, <em><span class="n">c</span><span class="o">=</span><span class="default_value">343.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#doas2taus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.doas2taus" title="Permalink to this definition">¶</a></dt>
<dd><p>This function converts directions of arrival (xyz coordinates
expressed in meters) in time differences of arrival (expressed in
samples). The result has the following format: (batch, time_steps, n_mics).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>doas</strong> (<em>tensor</em>) – The directions of arrival expressed with cartesian coordinates (xyz)
in meters. The tensor must have the following format: (batch, time_steps, 3).</li>
<li><strong>mics</strong> (<em>tensor</em>) – The cartesian position (xyz) in meters of each microphone.
The tensor must have the following format (n_mics, 3).</li>
<li><strong>fs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The sample rate in Hertz of the signals.</li>
<li><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The speed of sound in the medium. The speed is expressed in meters
per second and the default value of this parameter is 343 m/s.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">sphere</span><span class="p">,</span> <span class="n">doas2taus</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">2</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mics</span><span class="p">[</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">+</span><span class="mf">0.00</span><span class="p">])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">sphere</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">taus</span> <span class="o">=</span> <span class="n">doas2taus</span><span class="p">(</span><span class="n">doas</span><span class="p">,</span> <span class="n">mics</span><span class="p">,</span> <span class="n">fs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.processing.multi_mic.tdoas2taus">
<code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">tdoas2taus</code><span class="sig-paren">(</span><em><span class="n">tdoas</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#tdoas2taus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.tdoas2taus" title="Permalink to this definition">¶</a></dt>
<dd><p>This function selects the tdoas of each channel and put them
in a tensor. The result has the following format:
(batch, time_steps, n_mics).</p>
<dl class="docutils">
<dt>tdoas<span class="classifier">tensor</span></dt><dd>The time difference of arrival (TDOA) (in samples) for
each timestamp. The tensor has the format
(batch, time_steps, n_mics + n_pairs).</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.features</span> <span class="k">import</span> <span class="n">STFT</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">Covariance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">GccPhat</span><span class="p">,</span> <span class="n">tdoas2taus</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_speech</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span>
<span class="gp">... </span>   <span class="s1">&#39;samples/audio_samples/multi_mic/speech_-0.82918_0.55279_-0.082918.flac&#39;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs_noise</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/multi_mic/noise_diffuse.flac&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs_speech</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">xs_noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">xs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fs</span> <span class="o">=</span> <span class="mi">16000</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">taus</span> <span class="o">=</span> <span class="n">tdoas2taus</span><span class="p">(</span><span class="n">tdoas</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.processing.multi_mic.steering">
<code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">steering</code><span class="sig-paren">(</span><em><span class="n">taus</span></em>, <em><span class="n">n_fft</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#steering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.steering" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes a steering vector by using the time differences
of arrival for each channel (in samples) and the number of bins (n_fft).
The result has the following format: (batch, time_step, n_fft/2 + 1, 2, n_mics).</p>
<dl class="docutils">
<dt>taus<span class="classifier">tensor</span></dt><dd>The time differences of arrival for each channel. The tensor must have
the following format: (batch, time_steps, n_mics).</dd>
<dt>n_fft<span class="classifier">int</span></dt><dd>The number of bins resulting of the STFT. It is assumed that the
argument “onesided” was set to True for the STFT.</dd>
</dl>
<p>Example:
——–f
&gt;&gt;&gt; import torch
&gt;&gt;&gt; from speechbrain.dataio.dataio import read_audio
&gt;&gt;&gt; from speechbrain.processing.features import STFT
&gt;&gt;&gt; from speechbrain.processing.multi_mic import Covariance
&gt;&gt;&gt; from speechbrain.processing.multi_mic import GccPhat, tdoas2taus, steering
&gt;&gt;&gt;
&gt;&gt;&gt; xs_speech = read_audio(
…    ‘samples/audio_samples/multi_mic/<a href="#id1"><span class="problematic" id="id2">speech_</span></a>-<a href="#id3"><span class="problematic" id="id4">0.82918_0.55279_</span></a>-0.082918.flac’
… )
&gt;&gt;&gt; xs_noise = read_audio(‘samples/audio_samples/multi_mic/noise_diffuse.flac’)
&gt;&gt;&gt; xs = xs_speech + 0.05 * xs_noise
&gt;&gt;&gt; xs = xs.unsqueeze(0) # [batch, time, channels]
&gt;&gt;&gt; fs = 16000</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stft</span> <span class="o">=</span> <span class="n">STFT</span><span class="p">(</span><span class="n">sample_rate</span><span class="o">=</span><span class="n">fs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cov</span> <span class="o">=</span> <span class="n">Covariance</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gccphat</span> <span class="o">=</span> <span class="n">GccPhat</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Xs</span> <span class="o">=</span> <span class="n">stft</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">XXs</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tdoas</span> <span class="o">=</span> <span class="n">gccphat</span><span class="p">(</span><span class="n">XXs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">taus</span> <span class="o">=</span> <span class="n">tdoas2taus</span><span class="p">(</span><span class="n">tdoas</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">As</span> <span class="o">=</span> <span class="n">steering</span><span class="p">(</span><span class="n">taus</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt id="speechbrain.processing.multi_mic.sphere">
<code class="descclassname">speechbrain.processing.multi_mic.</code><code class="descname">sphere</code><span class="sig-paren">(</span><em><span class="n">levels_count</span><span class="o">=</span><span class="default_value">4</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/multi_mic.html#sphere"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.multi_mic.sphere" title="Permalink to this definition">¶</a></dt>
<dd><p>This function generates cartesian coordinates (xyz) for a set
of points forming a 3D sphere. The coordinates are expressed in
meters and can be used as doas. The result has the format:
(n_points, 3).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>levels_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – <p>A number proportional to the number of points that the user
wants to generate.</p>
<blockquote>
<div><ul class="simple">
<li>If levels_count = 1, then the sphere will have 42 points</li>
<li>If levels_count = 2, then the sphere will have 162 points</li>
<li>If levels_count = 3, then the sphere will have 642 points</li>
<li>If levels_count = 4, then the sphere will have 2562 points</li>
<li>If levels_count = 5, then the sphere will have 10242 points</li>
<li>…</li>
</ul>
</div></blockquote>
<p>By default, levels_count is set to 4.</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.processing.multi_mic</span> <span class="k">import</span> <span class="n">sphere</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">doas</span> <span class="o">=</span> <span class="n">sphere</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="speechbrain.processing.signal_processing.html" class="btn btn-neutral float-right" title="speechbrain.processing.signal_processing module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="speechbrain.processing.features.html" class="btn btn-neutral float-left" title="speechbrain.processing.features module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, SpeechBrain

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>