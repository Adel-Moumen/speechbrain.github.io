

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>speechbrain.processing.speech_augmentation module &mdash; SpeechBrain 0.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="speechbrain.tokenizers" href="speechbrain.tokenizers.html" />
    <link rel="prev" title="speechbrain.processing.signal_processing module" href="speechbrain.processing.signal_processing.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SpeechBrain
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Quick installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-via-pypi">Install via PyPI</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-locally">Install locally</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#test-installation">Test Installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experiment.html">Running an experiment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#yaml-basics">YAML basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#running-arguments">Running arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="experiment.html#tensor-format">Tensor format</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multigpu.html">Basics of multi-GPU</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-data-parallel">Multi-GPU training using Data Parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="multigpu.html#multi-gpu-training-using-distributed-data-parallel-ddp">Multi-GPU training using Distributed Data Parallel (DDP)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multigpu.html#with-multiple-machines-suppose-you-have-2-servers-with-2-gpus">With multiple machines (suppose you have 2 servers with 2 GPUs):</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#zen-of-speechbrain">Zen of Speechbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#how-to-get-your-code-in-speechbrain">How to get your code in SpeechBrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#python">Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#version">Version</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#formatting">Formatting</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#adding-dependencies">Adding dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#testing">Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation">Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#development-tools">Development tools</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#flake8">flake8</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pre-commit">pre-commit</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-commit-hooks">the git pre-commit hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#the-git-pre-push-hooks">the git pre-push hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#pytest-doctests">pytest doctests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#continuous-integration">Continuous integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#what-is-ci">What is CI?</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#ci-cd-pipelines">CI / CD Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#our-test-suite">Our test suite</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#pull-request-review-guide">Pull Request review guide</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">API Documentation:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="speechbrain.html">Core library (speechbrain)</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="speechbrain.core.html">speechbrain.core module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.core.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.yaml.html">speechbrain.yaml module</a></li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.alignment.html">speechbrain.alignment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.alignment.aligner.html">speechbrain.alignment.aligner module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.alignment.aligner.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.dataio.html">speechbrain.dataio</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.batch.html">speechbrain.dataio.batch module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.batch.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataio.html">speechbrain.dataio.dataio module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataloader.html">speechbrain.dataio.dataloader module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataloader.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.dataset.html">speechbrain.dataio.dataset module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.dataset.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.encoder.html">speechbrain.dataio.encoder module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.encoder.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.legacy.html">speechbrain.dataio.legacy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.legacy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.sampler.html">speechbrain.dataio.sampler module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.sampler.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.wer.html">speechbrain.dataio.wer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.dataio.wer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.dataio.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.decoders.html">speechbrain.decoders</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.ctc.html">speechbrain.decoders.ctc module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.ctc.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.seq2seq.html">speechbrain.decoders.seq2seq module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.seq2seq.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.decoders.transducer.html">speechbrain.decoders.transducer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.decoders.transducer.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lm.html">speechbrain.lm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.arpa.html">speechbrain.lm.arpa module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.arpa.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.counting.html">speechbrain.lm.counting module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.counting.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lm.ngram.html">speechbrain.lm.ngram module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lm.ngram.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.lobes.html">speechbrain.lobes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.augment.html">speechbrain.lobes.augment module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.augment.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.features.html">speechbrain.lobes.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.lobes.models.html">speechbrain.lobes.models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.CRDNN.html">speechbrain.lobes.models.CRDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ContextNet.html">speechbrain.lobes.models.ContextNet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ECAPA_TDNN.html">speechbrain.lobes.models.ECAPA_TDNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.ESPnetVGG.html">speechbrain.lobes.models.ESPnetVGG module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.MetricGAN_D.html">speechbrain.lobes.models.MetricGAN_D module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.RNNLM.html">speechbrain.lobes.models.RNNLM module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.VanillaNN.html">speechbrain.lobes.models.VanillaNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.Xvector.html">speechbrain.lobes.models.Xvector module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.conv_tasnet.html">speechbrain.lobes.models.conv_tasnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.convolution.html">speechbrain.lobes.models.convolution module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.dual_path.html">speechbrain.lobes.models.dual_path module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.lobes.models.transformer.html">speechbrain.lobes.models.transformer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.nnet.html">speechbrain.nnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.CNN.html">speechbrain.nnet.CNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.CNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.RNN.html">speechbrain.nnet.RNN module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.RNN.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.activations.html">speechbrain.nnet.activations module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.activations.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.attention.html">speechbrain.nnet.attention module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.attention.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.containers.html">speechbrain.nnet.containers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.containers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.dropout.html">speechbrain.nnet.dropout module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.dropout.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.embedding.html">speechbrain.nnet.embedding module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.embedding.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.linear.html">speechbrain.nnet.linear module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.linear.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.losses.html">speechbrain.nnet.losses module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.losses.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.normalization.html">speechbrain.nnet.normalization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.normalization.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.pooling.html">speechbrain.nnet.pooling module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.pooling.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.schedulers.html">speechbrain.nnet.schedulers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.schedulers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.complex_networks.html">speechbrain.nnet.complex_networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_CNN.html">speechbrain.nnet.complex_networks.c_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_RNN.html">speechbrain.nnet.complex_networks.c_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_linear.html">speechbrain.nnet.complex_networks.c_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_normalization.html">speechbrain.nnet.complex_networks.c_normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.complex_networks.c_ops.html">speechbrain.nnet.complex_networks.c_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.loss.html">speechbrain.nnet.loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.stoi_loss.html">speechbrain.nnet.loss.stoi_loss module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.loss.transducer_loss.html">speechbrain.nnet.loss.transducer_loss module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.html">speechbrain.nnet.quaternion_networks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_CNN.html">speechbrain.nnet.quaternion_networks.q_CNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_RNN.html">speechbrain.nnet.quaternion_networks.q_RNN module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_linear.html">speechbrain.nnet.quaternion_networks.q_linear module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_normalization.html">speechbrain.nnet.quaternion_networks.q_normalization module</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.quaternion_networks.q_ops.html">speechbrain.nnet.quaternion_networks.q_ops module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.transducer.html">speechbrain.nnet.transducer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.nnet.transducer.transducer_joint.html">speechbrain.nnet.transducer.transducer_joint module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.nnet.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="speechbrain.processing.html">speechbrain.processing</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.NMF.html">speechbrain.processing.NMF module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.NMF.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html">speechbrain.processing.PLDA_LDA module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.PLDA_LDA.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.decomposition.html">speechbrain.processing.decomposition module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.decomposition.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.diarization.html">speechbrain.processing.diarization module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#reference">Reference</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.diarization.html#id1">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.features.html">speechbrain.processing.features module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.features.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.multi_mic.html">speechbrain.processing.multi_mic module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.multi_mic.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.multi_mic.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.processing.signal_processing.html">speechbrain.processing.signal_processing module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.processing.signal_processing.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">speechbrain.processing.speech_augmentation module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.tokenizers.html">speechbrain.tokenizers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html">speechbrain.tokenizers.SentencePiece module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.tokenizers.SentencePiece.html#reference">Reference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.utils.html">speechbrain.utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.Accuracy.html">speechbrain.utils.Accuracy module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.Accuracy.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.DER.html">speechbrain.utils.DER module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.DER.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.checkpoints.html">speechbrain.utils.checkpoints module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.checkpoints.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.convert_model.html">speechbrain.utils.convert_model module</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_pipeline.html">speechbrain.utils.data_pipeline module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_pipeline.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.data_utils.html">speechbrain.utils.data_utils module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.data_utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.depgraph.html">speechbrain.utils.depgraph module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.depgraph.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.distributed.html">speechbrain.utils.distributed module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.distributed.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.edit_distance.html">speechbrain.utils.edit_distance module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.edit_distance.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.epoch_loop.html">speechbrain.utils.epoch_loop module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.epoch_loop.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.logger.html">speechbrain.utils.logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.metric_stats.html">speechbrain.utils.metric_stats module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.metric_stats.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html">speechbrain.utils.parameter_transfer module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.parameter_transfer.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.superpowers.html">speechbrain.utils.superpowers module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.superpowers.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.train_logger.html">speechbrain.utils.train_logger module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#summary">Summary</a></li>
<li class="toctree-l4"><a class="reference internal" href="speechbrain.utils.train_logger.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#summary">Summary</a></li>
<li class="toctree-l3"><a class="reference internal" href="speechbrain.utils.html#reference">Reference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="speechbrain.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">Runnable Tools (tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tools.compute_wer.html">tools.compute_wer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tools.compute_wer.html#usage">Usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SpeechBrain</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="speechbrain.html">speechbrain</a> &raquo;</li>
        
          <li><a href="speechbrain.processing.html">speechbrain.processing</a> &raquo;</li>
        
      <li>speechbrain.processing.speech_augmentation module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/speechbrain.processing.speech_augmentation.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-speechbrain.processing.speech_augmentation">
<span id="speechbrain-processing-speech-augmentation-module"></span><h1>speechbrain.processing.speech_augmentation module<a class="headerlink" href="#module-speechbrain.processing.speech_augmentation" title="Permalink to this headline">¶</a></h1>
<p>Classes for mutating speech data for data augmentation.</p>
<p>This module provides classes that produce realistic distortions of speech
data for the purpose of training speech processing models. The list of
distortions includes adding noise, adding reverberation, changing speed,
and more. All the classes are of type <cite>torch.nn.Module</cite>. This gives the
possibility to have end-to-end differentiability and
backpropagate the gradient through them. In addition, all operations
are expected to be performed on the GPU (where available) for efficiency.</p>
<dl class="docutils">
<dt>Authors</dt><dd><ul class="simple">
<li>Peter Plantinga 2020</li>
</ul>
</dd>
</dl>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Classes:</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.AddBabble" title="speechbrain.processing.speech_augmentation.AddBabble"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AddBabble</span></code></a></td>
<td>Simulate babble noise by mixing the signals in a batch.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.AddNoise" title="speechbrain.processing.speech_augmentation.AddNoise"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AddNoise</span></code></a></td>
<td>This class additively combines a noise signal to the input signal.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.AddReverb" title="speechbrain.processing.speech_augmentation.AddReverb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AddReverb</span></code></a></td>
<td>This class convolves an audio signal with an impulse response.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.DoClip" title="speechbrain.processing.speech_augmentation.DoClip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DoClip</span></code></a></td>
<td>This function mimics audio clipping by clamping the input tensor.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.DropChunk" title="speechbrain.processing.speech_augmentation.DropChunk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DropChunk</span></code></a></td>
<td>This class drops portions of the input signal.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.DropFreq" title="speechbrain.processing.speech_augmentation.DropFreq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DropFreq</span></code></a></td>
<td>This class drops a random frequency from the signal.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.Resample" title="speechbrain.processing.speech_augmentation.Resample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Resample</span></code></a></td>
<td>This class resamples an audio signal using sinc-based interpolation.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#speechbrain.processing.speech_augmentation.SpeedPerturb" title="speechbrain.processing.speech_augmentation.SpeedPerturb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SpeedPerturb</span></code></a></td>
<td>Slightly speed up or slow down an audio signal.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.AddNoise">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">AddNoise</code><span class="sig-paren">(</span><em><span class="n">csv_file</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">csv_keys</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">sorting</span><span class="o">=</span><span class="default_value">'random'</span></em>, <em><span class="n">num_workers</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">snr_low</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">snr_high</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">pad_noise</span><span class="o">=</span><span class="default_value">False</span></em>, <em><span class="n">mix_prob</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em><span class="n">start_index</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">normalize</span><span class="o">=</span><span class="default_value">False</span></em>, <em><span class="n">replacements</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddNoise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddNoise" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class additively combines a noise signal to the input signal.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>csv_file</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The name of a csv file containing the location of the
noise audio files. If none is provided, white noise will be used.</li>
<li><strong>csv_keys</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.9)"><em>None</em></a><em>, </em><em>optional</em>) – Default: None . One data entry for the noise data should be specified.
If None, the csv file is expected to have only one data entry.</li>
<li><strong>sorting</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The order to iterate the csv file, from one of the
following options: random, original, ascending, and descending.</li>
<li><strong>num_workers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of workers in the DataLoader (See PyTorch DataLoader docs).</li>
<li><strong>snr_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The low end of the mixing ratios, in decibels.</li>
<li><strong>snr_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The high end of the mixing ratios, in decibels.</li>
<li><strong>pad_noise</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – If True, copy noise signals that are shorter than
their corresponding clean signals so as to cover the whole clean
signal. Otherwise, leave the noise un-padded.</li>
<li><strong>mix_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The probability that a batch of signals will be mixed
with a noise signal. By default, every batch is mixed with noise.</li>
<li><strong>start_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The index in the noise waveforms to start from. By default, chooses
a random index in [0, len(noise) - len(waveforms)].</li>
<li><strong>normalize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – If True, output noisy signals that exceed [-1,1] will be
normalized to [-1,1].</li>
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a>) – A set of string replacements to carry out in the
csv file. Each time a key is found in the text, it will be replaced
with the corresponding value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clean</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noisifier</span> <span class="o">=</span> <span class="n">AddNoise</span><span class="p">(</span><span class="s1">&#39;samples/noise_samples/noise.csv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noisy</span> <span class="o">=</span> <span class="n">noisifier</span><span class="p">(</span><span class="n">clean</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.AddNoise.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em>, <em><span class="n">lengths</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddNoise.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddNoise.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – Shape should be a single dimension, <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.AddNoise.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddNoise.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.AddReverb">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">AddReverb</code><span class="sig-paren">(</span><em><span class="n">csv_file</span></em>, <em><span class="n">sorting</span><span class="o">=</span><span class="default_value">'random'</span></em>, <em><span class="n">reverb_prob</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em><span class="n">rir_scale_factor</span><span class="o">=</span><span class="default_value">1.0</span></em>, <em><span class="n">replacements</span><span class="o">=</span><span class="default_value">{}</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddReverb"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddReverb" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class convolves an audio signal with an impulse response.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>csv_file</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The name of a csv file containing the location of the
impulse response files.</li>
<li><strong>sorting</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The order to iterate the csv file, from one of
the following options: random, original, ascending, and descending.</li>
<li><strong>reverb_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The chance that the audio signal will be reverbed.
By default, every batch is reverbed.</li>
<li><strong>rir_scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – It compresses or dilates the given impulse response.
If 0 &lt; scale_factor &lt; 1, the impulse response is compressed
(less reverb), while if scale_factor &gt; 1 it is dilated
(more reverb).</li>
<li><strong>replacements</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a>) – A set of string replacements to carry out in the
csv file. Each time a key is found in the text, it will be replaced
with the corresponding value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clean</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reverb</span> <span class="o">=</span> <span class="n">AddReverb</span><span class="p">(</span><span class="s1">&#39;samples/rir_samples/rirs.csv&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reverbed</span> <span class="o">=</span> <span class="n">reverb</span><span class="p">(</span><span class="n">clean</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.AddReverb.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em>, <em><span class="n">lengths</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddReverb.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddReverb.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – Shape should be a single dimension, <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.AddReverb.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddReverb.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.SpeedPerturb">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">SpeedPerturb</code><span class="sig-paren">(</span><em><span class="n">orig_freq</span></em>, <em><span class="n">speeds</span><span class="o">=</span><span class="default_value">[90, 100, 110]</span></em>, <em><span class="n">perturb_prob</span><span class="o">=</span><span class="default_value">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#SpeedPerturb"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.SpeedPerturb" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Slightly speed up or slow down an audio signal.</p>
<p>Resample the audio signal at a rate that is similar to the original rate,
to achieve a slightly slower or slightly faster signal. This technique is
outlined in the paper: “Audio Augmentation for Speech Recognition”</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>orig_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The frequency of the original signal.</li>
<li><strong>speeds</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – The speeds that the signal should be changed to, as a percentage of the
original signal (i.e. <cite>speeds</cite> is divided by 100 to get a ratio).</li>
<li><strong>perturb_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The chance that the batch will be speed-
perturbed. By default, every batch is perturbed.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perturbator</span> <span class="o">=</span> <span class="n">SpeedPerturb</span><span class="p">(</span><span class="n">orig_freq</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">speeds</span><span class="o">=</span><span class="p">[</span><span class="mi">90</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clean</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perturbed</span> <span class="o">=</span> <span class="n">perturbator</span><span class="p">(</span><span class="n">clean</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clean</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 52173])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">perturbed</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 46956])</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.SpeedPerturb.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveform</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#SpeedPerturb.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.SpeedPerturb.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – Shape should be a single dimension, <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.SpeedPerturb.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.SpeedPerturb.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.Resample">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">Resample</code><span class="sig-paren">(</span><em><span class="n">orig_freq</span><span class="o">=</span><span class="default_value">16000</span></em>, <em><span class="n">new_freq</span><span class="o">=</span><span class="default_value">16000</span></em>, <em><span class="n">lowpass_filter_width</span><span class="o">=</span><span class="default_value">6</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#Resample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.Resample" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class resamples an audio signal using sinc-based interpolation.</p>
<p>It is a modification of the <cite>resample</cite> function from torchaudio
(<a class="reference external" href="https://pytorch.org/audio/transforms.html#resample">https://pytorch.org/audio/transforms.html#resample</a>)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>orig_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – the sampling frequency of the input signal.</li>
<li><strong>new_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – the new sampling frequency after this operation is performed.</li>
<li><strong>lowpass_filter_width</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Controls the sharpness of the filter, larger numbers result in a
sharper filter, but they are less efficient. Values from 4 to 10 are
allowed.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resampler</span> <span class="o">=</span> <span class="n">Resample</span><span class="p">(</span><span class="n">orig_freq</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resampled</span> <span class="o">=</span> <span class="n">resampler</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 52173])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">resampled</span><span class="o">.</span><span class="n">shape</span>
<span class="go">torch.Size([1, 26087])</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.Resample.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#Resample.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.Resample.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – Shape should be a single dimension, <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.Resample.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.Resample.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.AddBabble">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">AddBabble</code><span class="sig-paren">(</span><em><span class="n">speaker_count</span><span class="o">=</span><span class="default_value">3</span></em>, <em><span class="n">snr_low</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">snr_high</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">mix_prob</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddBabble"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddBabble" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Simulate babble noise by mixing the signals in a batch.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>speaker_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of signals to mix with the original signal.</li>
<li><strong>snr_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The low end of the mixing ratios, in decibels.</li>
<li><strong>snr_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The high end of the mixing ratios, in decibels.</li>
<li><strong>mix_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The probability that the batch of signals will be
mixed with babble noise. By default, every signal is mixed.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pytest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">babbler</span> <span class="o">=</span> <span class="n">AddBabble</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">ExtendedCSVDataset</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">csvpath</span><span class="o">=</span><span class="s1">&#39;samples/audio_samples/csv_example3.csv&#39;</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loader</span> <span class="o">=</span> <span class="n">make_dataloader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">speech</span><span class="p">,</span> <span class="n">lengths</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span><span class="o">.</span><span class="n">at_position</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">noisy</span> <span class="o">=</span> <span class="n">babbler</span><span class="p">(</span><span class="n">speech</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.AddBabble.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em>, <em><span class="n">lengths</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#AddBabble.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddBabble.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – A batch of audio signals to process, with shape <cite>[batch, time]</cite> or
<cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – The length of each audio in the batch, with shape <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor with processed waveforms.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.AddBabble.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.AddBabble.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.DropFreq">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">DropFreq</code><span class="sig-paren">(</span><em><span class="n">drop_freq_low</span><span class="o">=</span><span class="default_value">1e-14</span></em>, <em><span class="n">drop_freq_high</span><span class="o">=</span><span class="default_value">1</span></em>, <em><span class="n">drop_count_low</span><span class="o">=</span><span class="default_value">1</span></em>, <em><span class="n">drop_count_high</span><span class="o">=</span><span class="default_value">2</span></em>, <em><span class="n">drop_width</span><span class="o">=</span><span class="default_value">0.05</span></em>, <em><span class="n">drop_prob</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DropFreq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropFreq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class drops a random frequency from the signal.</p>
<p>The purpose of this class is to teach models to learn to rely on all parts
of the signal, not just a few frequency bands.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>drop_freq_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The low end of frequencies that can be dropped,
as a fraction of the sampling rate / 2.</li>
<li><strong>drop_freq_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The high end of frequencies that can be
dropped, as a fraction of the sampling rate / 2.</li>
<li><strong>drop_count_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The low end of number of frequencies that could be dropped.</li>
<li><strong>drop_count_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The high end of number of frequencies that could be dropped.</li>
<li><strong>drop_width</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The width of the frequency band to drop, as
a fraction of the sampling_rate / 2.</li>
<li><strong>drop_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The probability that the batch of signals will  have a frequency
dropped. By default, every batch has frequencies dropped.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropper</span> <span class="o">=</span> <span class="n">DropFreq</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropped_signal</span> <span class="o">=</span> <span class="n">dropper</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.DropFreq.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DropFreq.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropFreq.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.DropFreq.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropFreq.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.DropChunk">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">DropChunk</code><span class="sig-paren">(</span><em><span class="n">drop_length_low</span><span class="o">=</span><span class="default_value">100</span></em>, <em><span class="n">drop_length_high</span><span class="o">=</span><span class="default_value">1000</span></em>, <em><span class="n">drop_count_low</span><span class="o">=</span><span class="default_value">1</span></em>, <em><span class="n">drop_count_high</span><span class="o">=</span><span class="default_value">10</span></em>, <em><span class="n">drop_start</span><span class="o">=</span><span class="default_value">0</span></em>, <em><span class="n">drop_end</span><span class="o">=</span><span class="default_value">None</span></em>, <em><span class="n">drop_prob</span><span class="o">=</span><span class="default_value">1</span></em>, <em><span class="n">noise_factor</span><span class="o">=</span><span class="default_value">0.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DropChunk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropChunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This class drops portions of the input signal.</p>
<p>Using <cite>DropChunk</cite> as an augmentation strategy helps a models learn to rely
on all parts of the signal, since it can’t expect a given part to be
present.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>drop_length_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The low end of lengths for which to set the
signal to zero, in samples.</li>
<li><strong>drop_length_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The high end of lengths for which to set the
signal to zero, in samples.</li>
<li><strong>drop_count_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The low end of number of times that the signal
can be dropped to zero.</li>
<li><strong>drop_count_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The high end of number of times that the signal
can be dropped to zero.</li>
<li><strong>drop_start</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The first index for which dropping will be allowed.</li>
<li><strong>drop_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The last index for which dropping will be allowed.</li>
<li><strong>drop_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The probability that the batch of signals will
have a portion dropped. By default, every batch
has portions dropped.</li>
<li><strong>noise_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The factor relative to average amplitude of an utterance
to use for scaling the white noise inserted. 1 keeps
the average amplitude the same, while 0 inserts all 0’s.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropper</span> <span class="o">=</span> <span class="n">DropChunk</span><span class="p">(</span><span class="n">drop_start</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">drop_end</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">noise_factor</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [batch, time, channels]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">length</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dropped_signal</span> <span class="o">=</span> <span class="n">dropper</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">length</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">dropped_signal</span><span class="p">[:,</span> <span class="mi">150</span><span class="p">])</span>
<span class="go">0.0</span>
</pre></div>
</div>
<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.DropChunk.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em>, <em><span class="n">lengths</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DropChunk.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropChunk.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</li>
<li><strong>lengths</strong> (<em>tensor</em>) – Shape should be a single dimension, <cite>[batch]</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><cite>[batch, time, channels]</cite></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Tensor of shape <cite>[batch, time]</cite> or</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.DropChunk.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DropChunk.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="speechbrain.processing.speech_augmentation.DoClip">
<em class="property">class </em><code class="descclassname">speechbrain.processing.speech_augmentation.</code><code class="descname">DoClip</code><span class="sig-paren">(</span><em><span class="n">clip_low</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em><span class="n">clip_high</span><span class="o">=</span><span class="default_value">1</span></em>, <em><span class="n">clip_prob</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DoClip"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DoClip" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This function mimics audio clipping by clamping the input tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>clip_low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The low end of amplitudes for which to clip the signal.</li>
<li><strong>clip_high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The high end of amplitudes for which to clip the signal.</li>
<li><strong>clip_prob</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The probability that the batch of signals will have a portion clipped.
By default, every batch has portions clipped.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">speechbrain.dataio.dataio</span> <span class="k">import</span> <span class="n">read_audio</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clipper</span> <span class="o">=</span> <span class="n">DoClip</span><span class="p">(</span><span class="n">clip_low</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">clip_high</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal</span> <span class="o">=</span> <span class="n">read_audio</span><span class="p">(</span><span class="s1">&#39;samples/audio_samples/example1.wav&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clipped_signal</span> <span class="o">=</span> <span class="n">clipper</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="s2">&quot;</span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">clipped_signal</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="go">&#39;0.01&#39;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt id="speechbrain.processing.speech_augmentation.DoClip.training">
<code class="descname">training</code><em class="property">: <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a></em><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DoClip.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="speechbrain.processing.speech_augmentation.DoClip.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em><span class="n">waveforms</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/speechbrain/processing/speech_augmentation.html#DoClip.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#speechbrain.processing.speech_augmentation.DoClip.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>waveforms</strong> (<em>tensor</em>) – Shape should be <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">Tensor of shape <cite>[batch, time]</cite> or <cite>[batch, time, channels]</cite></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="speechbrain.tokenizers.html" class="btn btn-neutral float-right" title="speechbrain.tokenizers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="speechbrain.processing.signal_processing.html" class="btn btn-neutral float-left" title="speechbrain.processing.signal_processing module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, SpeechBrain

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>